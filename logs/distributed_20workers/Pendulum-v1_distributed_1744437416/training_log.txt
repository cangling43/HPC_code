训练开始时间: 2025-04-12 13:57:18
日志目录: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416
--------------------------------------------------

更新: 1/195, 步数: 10240/2000000
平均奖励: -1350.67, 最近100回合平均: -1350.67
策略损失: -0.0001, 价值损失: 10669.6149, 熵: 0.7208
FPS: 6680.6, 预计剩余时间: 4分 57秒

更新: 10/195, 步数: 102400/2000000
平均奖励: -1328.37, 最近100回合平均: -1328.37
策略损失: 0.0001, 价值损失: 6471.9367, 熵: 0.7112
FPS: 6501.5, 预计剩余时间: 4分 51秒

更新: 20/195, 步数: 204800/2000000
平均奖励: -1272.16, 最近100回合平均: -1272.16
策略损失: -0.0007, 价值损失: 5485.7593, 熵: 0.7214
FPS: 6490.2, 预计剩余时间: 4分 36秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_256000.pt
模型已保存: 最佳模型: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\best_model.pt (奖励: -1286.59)

更新: 30/195, 步数: 307200/2000000
平均奖励: -1270.42, 最近100回合平均: -1270.42
策略损失: 0.0000, 价值损失: 5207.7164, 熵: 0.7304
FPS: 6529.3, 预计剩余时间: 4分 18秒

更新: 40/195, 步数: 409600/2000000
平均奖励: -1256.49, 最近100回合平均: -1256.49
策略损失: 0.0007, 价值损失: 7037.0462, 熵: 0.7179
FPS: 6455.0, 预计剩余时间: 4分 5秒
参数自动调整历史:
- 初始化: 环境: Pendulum-v1 

当前参数状态:
- 学习率: 0.000300
- 熵系数: 0.007952
- 梯度裁剪: 0.75
- 最佳奖励: -1247.25


更新: 50/195, 步数: 512000/2000000
平均奖励: -1257.35, 最近100回合平均: -1257.35
策略损失: -0.0005, 价值损失: 7731.1551, 熵: 0.7079
FPS: 6387.7, 预计剩余时间: 3分 52秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_512000.pt
模型已保存: 最佳模型: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\best_model.pt (奖励: -1257.35)

更新: 60/195, 步数: 614400/2000000
平均奖励: -1260.03, 最近100回合平均: -1260.03
策略损失: 0.0024, 价值损失: 4941.0698, 熵: 0.7061
FPS: 6378.3, 预计剩余时间: 3分 36秒

更新: 70/195, 步数: 716800/2000000
平均奖励: -1255.31, 最近100回合平均: -1255.31
策略损失: 0.0018, 价值损失: 6218.0164, 熵: 0.6826
FPS: 6409.0, 预计剩余时间: 3分 19秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_768000.pt

更新: 80/195, 步数: 819200/2000000
平均奖励: -1259.17, 最近100回合平均: -1259.17
策略损失: 0.0038, 价值损失: 4483.6725, 熵: 0.6878
FPS: 6436.1, 预计剩余时间: 3分 2秒

更新: 90/195, 步数: 921600/2000000
平均奖励: -1231.94, 最近100回合平均: -1231.94
策略损失: 0.0014, 价值损失: 5322.6080, 熵: 0.7002
FPS: 6422.9, 预计剩余时间: 2分 47秒
参数自动调整历史:
- 初始化: 环境: Pendulum-v1 
- Pendulum优化: 调整学习率到 0.000300

当前参数状态:
- 学习率: 0.000300
- 熵系数: 0.005904
- 梯度裁剪: 0.75
- 最佳奖励: -1194.69


更新: 100/195, 步数: 1024000/2000000
平均奖励: -1194.69, 最近100回合平均: -1194.69
策略损失: 0.0002, 价值损失: 4531.7542, 熵: 0.6906
FPS: 6390.8, 预计剩余时间: 2分 32秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_1024000.pt
模型已保存: 最佳模型: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\best_model.pt (奖励: -1194.69)

更新: 110/195, 步数: 1126400/2000000
平均奖励: -1178.75, 最近100回合平均: -1178.75
策略损失: 0.0012, 价值损失: 3408.7472, 熵: 0.6767
FPS: 6383.1, 预计剩余时间: 2分 16秒

更新: 120/195, 步数: 1228800/2000000
平均奖励: -1229.52, 最近100回合平均: -1229.52
策略损失: 0.0002, 价值损失: 5234.0611, 熵: 0.6283
FPS: 6387.4, 预计剩余时间: 2分 0秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_1280000.pt

更新: 130/195, 步数: 1331200/2000000
平均奖励: -1177.17, 最近100回合平均: -1177.17
策略损失: 0.0021, 价值损失: 3715.1896, 熵: 0.6097
FPS: 6400.1, 预计剩余时间: 1分 43秒

更新: 140/195, 步数: 1433600/2000000
平均奖励: -1195.73, 最近100回合平均: -1195.73
策略损失: 0.0005, 价值损失: 4754.2175, 熵: 0.6104
FPS: 6392.4, 预计剩余时间: 1分 28秒
参数自动调整历史:
- 初始化: 环境: Pendulum-v1 
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300
- 训练后期停滞: 参数脉冲 lr=0.000300, ent=0.015000
- Pendulum优化: 调整学习率到 0.000300
- Pendulum优化: 调整学习率到 0.000300

当前参数状态:
- 学习率: 0.000300
- 熵系数: 0.003856
- 梯度裁剪: 0.75
- 最佳奖励: -1173.74


更新: 150/195, 步数: 1536000/2000000
平均奖励: -1200.83, 最近100回合平均: -1200.83
策略损失: -0.0002, 价值损失: 4987.6023, 熵: 0.5531
FPS: 6408.0, 预计剩余时间: 1分 11秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_1536000.pt

更新: 160/195, 步数: 1638400/2000000
平均奖励: -1221.67, 最近100回合平均: -1221.67
策略损失: 0.0012, 价值损失: 4150.0224, 熵: 0.5361
FPS: 6394.6, 预计剩余时间: 0分 56秒

更新: 170/195, 步数: 1740800/2000000
平均奖励: -1221.68, 最近100回合平均: -1221.68
策略损失: 0.0002, 价值损失: 5821.5596, 熵: 0.5018
FPS: 6393.2, 预计剩余时间: 0分 40秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_1792000.pt
模型已保存: 最佳模型: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\best_model.pt (奖励: -1187.43)

更新: 180/195, 步数: 1843200/2000000
平均奖励: -1202.49, 最近100回合平均: -1202.49
策略损失: 0.0016, 价值损失: 3759.9488, 熵: 0.4476
FPS: 6401.6, 预计剩余时间: 0分 23秒

更新: 190/195, 步数: 1945600/2000000
平均奖励: -1243.26, 最近100回合平均: -1243.26
策略损失: 0.0013, 价值损失: 5916.9814, 熵: 0.4359
FPS: 6415.9, 预计剩余时间: 0分 7秒
模型已保存: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\model_1996800.pt
模型已保存: 最终模型: ./logs/distributed_20workers\Pendulum-v1_distributed_1744437416\final_model.pt

训练结束时间: 2025-04-12 14:02:28


可视化分析时间: 2025-04-12 16:00:43

========== 训练结果分析 ==========
训练总步数: 1,945,600
最终平均奖励 (最近100回合): -1243.26
最高平均奖励 (最近100回合): -1177.17
奖励改进幅度: 0.00
平均每秒步数: 6432.88

训练质量评估:
✗ 奖励未达到期望水平 (< -400)
△ 损失函数波动较大
- 训练收敛性分析：数据不足

总体评估: 需要改进 ⭐
================================
